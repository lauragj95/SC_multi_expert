{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab485118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "from source.datasets import get_PANDA, CustomDataset\n",
    "from sklearn.decomposition import PCA\n",
    "from source.vision_transformer import vit_small, vit4k_xs\n",
    "from source.utils import update_state_dict\n",
    "import random \n",
    "from utils.dbscan_utils import get_core_expert,get_core_noncore_points\n",
    "from utils.distance_utils import calculate_distances\n",
    "from utils.patching_utils import get_patches\n",
    "from SC_maps_utils import get_silhouette_complete,get_outliers\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    cudnn.deterministic = True\n",
    "    cudnn.benchmark = True\n",
    "    print(device)\n",
    "    \n",
    "random.seed(0)\n",
    "dir = '/datadisk/datasets/PANDA/'\n",
    "img = ''\n",
    "expert = 'original'\n",
    "patch_size = 256\n",
    "region_size = 4096\n",
    "mini_patch_size = 16\n",
    "checkpoint_256 = '/checkpoints/vit_256_small_dino_fold_4.pt'\n",
    "checkpoint_4k = '/checkpoints/vit_4096_xs_dino_fold_4.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2661f754",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### DATASET #####\n",
    "train_data = get_PANDA(dir,expert=expert)\n",
    "train_dataset = CustomDataset(train_data)\n",
    "loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=1, shuffle=False,\n",
    "    num_workers=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "921a8f27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisionTransformer4K(\n",
       "  (phi): Sequential(\n",
       "    (0): Linear(in_features=384, out_features=192, bias=True)\n",
       "    (1): GELU(approximate='none')\n",
       "    (2): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "  (blocks): ModuleList(\n",
       "    (0-5): 6 x Block(\n",
       "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "  (head): Identity()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### SET MODELS ####\n",
    "vit_patch = vit_small(\n",
    "    img_size=patch_size,\n",
    "    patch_size=mini_patch_size,\n",
    "    embed_dim=384,\n",
    "    mask_attn=False,\n",
    "    num_register_tokens=0,\n",
    ")\n",
    "\n",
    "vit_region = vit4k_xs(\n",
    "    img_size=region_size,\n",
    "    patch_size=patch_size,\n",
    "    input_embed_dim=384,\n",
    "    output_embed_dim=192,\n",
    "    mask_attn=False\n",
    ")\n",
    "\n",
    "state_dict = torch.load(checkpoint_256, map_location=\"cpu\",weights_only=False)\n",
    "checkpoint_key = \"teacher\"\n",
    "if checkpoint_key is not None and checkpoint_key in state_dict:\n",
    "    state_dict = state_dict[checkpoint_key]\n",
    "# remove `module.` prefix\n",
    "state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n",
    "# remove `backbone.` prefix induced by multicrop wrapper\n",
    "state_dict = {k.replace(\"backbone.\", \"\"): v for k, v in state_dict.items()}\n",
    "state_dict, msg = update_state_dict(vit_patch.state_dict(), state_dict)\n",
    "vit_patch.load_state_dict(state_dict, strict=False)\n",
    "for name, param in vit_patch.named_parameters():\n",
    "    param.requires_grad = False\n",
    "vit_patch.to(device)\n",
    "vit_patch.eval()\n",
    "\n",
    "state_dict = torch.load(checkpoint_4k, map_location=\"cpu\",weights_only=False)\n",
    "if checkpoint_key is not None and checkpoint_key in state_dict:\n",
    "    state_dict = state_dict[checkpoint_key]\n",
    "# remove `module.` prefix\n",
    "state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n",
    "# remove `backbone.` prefix induced by multicrop wrapper\n",
    "state_dict = {k.replace(\"backbone.\", \"\"): v for k, v in state_dict.items()}\n",
    "state_dict, msg = update_state_dict(\n",
    "    vit_region.state_dict(), state_dict\n",
    ")\n",
    "vit_region.load_state_dict(state_dict, strict=False)\n",
    "for name, param in vit_region.named_parameters():\n",
    "    param.requires_grad = False\n",
    "vit_region.to(device)\n",
    "vit_region.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03424df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### GET FEATURES ####\n",
    "features = []\n",
    "labels = []\n",
    "for _,img,label in loader:\n",
    "        img = img.to(device)\n",
    "        label = label.to(device)\n",
    "        feat,label = get_patches(img,vit_patch,vit_region,patch_size,region_size,y=label,mode='both',region=True)\n",
    "        features.extend(feat.cpu().detach().numpy())\n",
    "        labels.append(label.cpu().detach().numpy())\n",
    "\n",
    "\n",
    "\n",
    "features_aux = []\n",
    "labels_aux = []\n",
    "idx_aux = []\n",
    "for i,lbl in enumerate(labels):\n",
    "    feat = features[i]\n",
    "    for j,label in enumerate(lbl):\n",
    "            features_aux.append(feat[j])\n",
    "            idx_aux.append(f'{i}_{j}')\n",
    "            labels_aux.append(np.unique(label))\n",
    "\n",
    "#### PCA ####\n",
    "pca = PCA(n_components=0.9)\n",
    "principalComponents = pca.fit_transform(features_aux)\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "total_variance = sum(list(explained_variance))*100\n",
    "\n",
    "\n",
    "knn_features = []\n",
    "knn_labels = []\n",
    "knn_idx = []\n",
    "for i,lbl in enumerate(labels_aux):\n",
    "    if (2 in lbl and 3 in lbl) or (2 in lbl and 5 in lbl) or (3 in lbl and 4 in lbl) or (3 in lbl and 5 in lbl) or (4 in lbl and 5 in lbl):\n",
    "        pass\n",
    "    else:\n",
    "        knn_features.append(principalComponents[i])\n",
    "        knn_idx.append(idx_aux[i])\n",
    "        if len(lbl)==1:\n",
    "            knn_labels.append(lbl[0])\n",
    "        else:\n",
    "            knn_labels.append(lbl[-1])\n",
    "\n",
    "\n",
    "###### DIVIDE BY CLASSES #####\n",
    "cl_0 = {}\n",
    "cl_1 = {}\n",
    "cl_2 = {}\n",
    "cl_3 = {}\n",
    "cl_4 = {}\n",
    "cl_5 = {}\n",
    "for i, idx in enumerate(knn_idx):\n",
    "    div_index = idx.split('_')\n",
    "    expert_ann = labels[int(div_index[0])][int(div_index[1])]\n",
    "    cl,count = np.unique(expert_ann,return_counts=True)\n",
    "    cl_counts = dict(zip(cl,count))\n",
    "    if len(cl)==1 and cl[0]==0:\n",
    "        cl_0[idx] = knn_features[i]\n",
    "    elif knn_labels[i] == 1 :\n",
    "        if cl_counts[1]/(256**2)>0.15 and 0 not in cl:\n",
    "            cl_1[idx] = knn_features[i]\n",
    "    elif knn_labels[i] == 2:\n",
    "        if cl_counts[2]/(256**2)>0.15 and 0 not in cl:\n",
    "            cl_2[idx] = knn_features[i]\n",
    "    elif knn_labels[i] == 3:\n",
    "        if cl_counts[3]/(256**2)>0.15 and 0 not in cl:\n",
    "            cl_3[idx] = knn_features[i] \n",
    "    elif knn_labels[i] == 4:\n",
    "        if cl_counts[4]/(256**2)>0.15 and 0 not in cl:\n",
    "            cl_4[idx] = knn_features[i] \n",
    "    elif knn_labels[i] == 5:\n",
    "        if cl_counts[5]/(256**2)>0.15 and 0 not in cl:\n",
    "            cl_5[idx] = knn_features[i] \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01c6076b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### DISTANCES #######\n",
    "dist0 = calculate_distances(cl_0)\n",
    "dist1 = calculate_distances(cl_1)\n",
    "dist2 = calculate_distances(cl_2)\n",
    "dist3 = calculate_distances(cl_3)\n",
    "dist4 = calculate_distances(cl_4)\n",
    "dist5 = calculate_distances(cl_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d37abc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids_orig,labels_orig,eps_orig,min_samples_orig = get_core_expert([cl_1,cl_2,cl_3,cl_4,cl_5],[dist1,dist2,dist3,dist4,dist5])\n",
    "outliers1 = get_outliers(labels_orig[0],cl_1)\n",
    "outliers2 = get_outliers(labels_orig[1],cl_2)\n",
    "outliers3 = get_outliers(labels_orig[2],cl_3)\n",
    "outliers4 = get_outliers(labels_orig[3],cl_4)\n",
    "outliers5 = get_outliers(labels_orig[4],cl_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e89d419",
   "metadata": {},
   "outputs": [],
   "source": [
    "core1,noncore1 = get_core_noncore_points(cl_1, centroids_orig[0],labels_orig[0])\n",
    "core2,noncore2 = get_core_noncore_points(cl_2, centroids_orig[1],labels_orig[1])\n",
    "core3,noncore3 = get_core_noncore_points(cl_3, centroids_orig[2],labels_orig[2])\n",
    "core4,noncore4 = get_core_noncore_points(cl_4, centroids_orig[3],labels_orig[3])\n",
    "core5,noncore5 = get_core_noncore_points(cl_5, centroids_orig[4],labels_orig[4])\n",
    "\n",
    "cores = [core1,core2,core3,core4,core5]\n",
    "s_core = get_silhouette_complete(cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3abba984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.17413855295250796,\n",
       " 0.04159586094312696,\n",
       " 0.03756258691151437,\n",
       " 0.2132521987462455,\n",
       " 0.10796689610440229]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sil1 = [0.1948883852802351,\n",
    " 0.04331368410891981,\n",
    " 0.09613475633285883,\n",
    " 0.2553953597061623,\n",
    " 0.1333708716583793]\n",
    "outliers1 = 752/7063\n",
    "outliers2 = 28/706\n",
    "outliers3 = 92/151\n",
    "outliers4 = 216/1309\n",
    "outliers5 = 8/42\n",
    "outliers = [outliers1,outliers2,outliers3,outliers4,outliers5]\n",
    "\n",
    "sc1 = [sil*(1-outlier) for sil,outlier in zip(sil1,outliers)]\n",
    "sc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "82d918e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1746215453883229,\n",
       " 0.09187176598765444,\n",
       " 0.015822051615389743,\n",
       " 0.13378459993830488,\n",
       " 0.11845875284839837]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sil2 = [0.19542892965896444,\n",
    " 0.09727598751633999,\n",
    " 0.017125044101363018,\n",
    " 0.16556768169160382,\n",
    " 0.14633140057743327]\n",
    "\n",
    "outliers1 = 752/7063\n",
    "outliers2 = 44/792\n",
    "outliers3 = 42/552\n",
    "outliers4 = 215/1120\n",
    "outliers5 = 8/42\n",
    "outliers = [outliers1,outliers2,outliers3,outliers4,outliers5]\n",
    "\n",
    "sc2 = [sil*(1-outlier) for sil,outlier in zip(sil2,outliers)]\n",
    "sc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c9895f13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.17350645981818066,\n",
       " 0.04427933669316397,\n",
       " 0.054165447146689624,\n",
       " 0.1791331354869694,\n",
       " 0.11459300211175519]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sil3 = [0.19418097380697355,\n",
    " 0.04553016541330985,\n",
    " 0.06461245162781215,\n",
    " 0.20946730372073477,\n",
    " 0.14155606143216817]\n",
    "\n",
    "outliers1 = 752/7063\n",
    "outliers2 = 20/728\n",
    "outliers3 = 92/569\n",
    "outliers4 = 169/1167\n",
    "outliers5 = 8/42\n",
    "outliers = [outliers1,outliers2,outliers3,outliers4,outliers5]\n",
    "\n",
    "sc3 = [sil*(1-outlier) for sil,outlier in zip(sil3,outliers)]\n",
    "sc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "72b0b346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.17213252730634207,\n",
       " 0.08359458045343011,\n",
       " 0.10913722688557902,\n",
       " 0.21234229719298392,\n",
       " 0.10910997665426424]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "silOrig = [0.19264332758115896,\n",
    " 0.08851190871539659,\n",
    " 0.13249770354336182,\n",
    " 0.2543056422924208,\n",
    " 0.13478291233762052\n",
    "]\n",
    "\n",
    "outliers1 = 752/7063\n",
    "outliers2 = 44/792\n",
    "outliers3 = 64/363\n",
    "outliers4 = 216/1309\n",
    "outliers5 = 8/42\n",
    "outliers = [outliers1,outliers2,outliers3,outliers4,outliers5]\n",
    "\n",
    "scOrig = [sil*(1-outlier) for sil,outlier in zip(silOrig,outliers)]\n",
    "scOrig"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
