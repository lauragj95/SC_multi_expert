{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference import segmentation_scores\n",
    "import os\n",
    "from torch.utils import data\n",
    "import utils.globals as globals\n",
    "import torch\n",
    "from data import InferenceDataset,get_preprocessing_fn_without_normalization,get_preprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from statsmodels.stats.descriptivestats import sign_test\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "    torch.cuda.set_device(1)\n",
    "else:\n",
    "    device = 'cpu'\n",
    "print(\"Running on \" + device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### PANDA #########\n",
    "\n",
    "class_no = 4\n",
    "ignore_classes = 0\n",
    "metrics_names = ['macro_dice', 'micro_dice', 'accuracy','brier']\n",
    "class_names = ['background','gleason1', 'gleason3', 'gleason4']\n",
    "dir =  '/datasets/PANDA/patches/'\n",
    "mode = 'smooth_Gleason'\n",
    "folder = 2\n",
    "c_weights = [0.9991,0.1188,0.9712,0.9109]\n",
    "model_path = f'/experiments/{mode}/{folder}/models/16.pth'\n",
    "imgs_dir = f'{dir}imgs'\n",
    "masks_dir = f'{dir}masks/original'\n",
    "all_results = {'macro_dice':[],\n",
    " 'micro_dice': [],\n",
    " 'dice_class_1_gleason1': [],\n",
    " 'dice_class_2_gleason3': [],\n",
    " 'dice_class_3_gleason4': [],\n",
    " 'f1_class_1_gleason1': [],\n",
    " 'f1_class_2_gleason3': [],\n",
    " 'f1_class_3_gleason4': [],\n",
    " 'prec_class_1_gleason1': [],\n",
    " 'prec_class_2_gleason3': [],\n",
    " 'prec_class_3_gleason4': [],\n",
    " 'recall_class_1_gleason1': [],\n",
    " 'recall_class_2_gleason3': [],\n",
    " 'recall_class_3_gleason4': [],\n",
    " 'brier': [],\n",
    " 'ce': [],\n",
    " 'accuracy': []}\n",
    "\n",
    "preprocessing_fn = get_preprocessing_fn_without_normalization()\n",
    "preprocessing = get_preprocessing(preprocessing_fn)\n",
    "test_dataset = InferenceDataset(imgs_dir, masks_dir, preprocessing = preprocessing)\n",
    "testloader = data.DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=1,\n",
    "                                 drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### GLEASON19 #########\n",
    "\n",
    "class_no = 4\n",
    "ignore_classes = 0\n",
    "metrics_names = ['macro_dice', 'micro_dice', 'accuracy','brier']\n",
    "class_names = ['background','gleason1', 'gleason3', 'gleason4']#, 'gleason5']\n",
    "dir =  '/datasets/Arvaniti/patches/'\n",
    "mode = 'sc_Gleason'\n",
    "folder = 2\n",
    "# c_weights = [0.934,0.958,0.799,0.422] #PATH2\n",
    "c_weights = [0.9744,0.9662,0.5803,0.5382] #PATH1\n",
    "model_path = f'/experiments/{mode}/{folder}/models/8.pth'\n",
    "imgs_dir = f'{dir}imgs/test'\n",
    "masks_dir = f'{dir}masks/path1'\n",
    "all_results = {'macro_dice':[],\n",
    " 'micro_dice': [],\n",
    " 'dice_class_1_gleason1': [],\n",
    " 'dice_class_2_gleason3': [],\n",
    " 'dice_class_3_gleason4': [],\n",
    " 'f1_class_1_gleason1': [],\n",
    " 'f1_class_2_gleason3': [],\n",
    " 'f1_class_3_gleason4': [],\n",
    " 'prec_class_1_gleason1': [],\n",
    " 'prec_class_2_gleason3': [],\n",
    " 'prec_class_3_gleason4': [],\n",
    " 'recall_class_1_gleason1': [],\n",
    " 'recall_class_2_gleason3': [],\n",
    " 'recall_class_3_gleason4': [],\n",
    " 'brier': [],\n",
    " 'ce': [],\n",
    " 'accuracy': []}\n",
    "\n",
    "preprocessing_fn = get_preprocessing_fn_without_normalization()\n",
    "preprocessing = get_preprocessing(preprocessing_fn)\n",
    "test_dataset = InferenceDataset(imgs_dir, masks_dir, data='Arvaniti', preprocessing = preprocessing)\n",
    "testloader = data.DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=1,\n",
    "                                 drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(model_path).to(device)\n",
    "model.eval()\n",
    "\n",
    "labels = []\n",
    "preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for j, (test_img, test_label, test_name, _) in enumerate(testloader):\n",
    "        test_img = test_img.to(device=device, dtype=torch.float32)\n",
    "        \n",
    "        pred = model(test_img)\n",
    "        merged_class = pred[:, 0, :, :] + pred[:, 4, :, :]\n",
    "\n",
    "        # Build new tensor with fewer classes (e.g., 5 classes)\n",
    "        new_output = torch.cat([    \n",
    "            merged_class.unsqueeze(1),  \n",
    "            pred[:, 1:4, :, :]           \n",
    "        ], dim=1)\n",
    "        pred = new_output\n",
    "        test_label[test_label==4]=0\n",
    "        loss = torch.nn.CrossEntropyLoss(weight=torch.FloatTensor(c_weights).cuda(),ignore_index=0,reduction='mean')(\n",
    "                        pred, test_label.cuda())\n",
    "\n",
    "        _, test_pred = torch.max(pred, dim=1)\n",
    "\n",
    "        \n",
    "        test_pred_np = test_pred.cpu().detach().numpy()\n",
    "        test_label = test_label.cpu().detach().numpy()\n",
    "   \n",
    "        preds.append(test_pred_np.astype(np.int8).copy().flatten())\n",
    "        labels.append(test_label.astype(np.int8).copy().flatten())\n",
    "        if test_label.sum()!=0:\n",
    "            all_results['ce'].append(loss.item())\n",
    "            \n",
    "    \n",
    "            results = segmentation_scores(test_label, test_pred_np, metrics_names,class_names=class_names,class_no=class_no,weights=c_weights,ignore_class=ignore_classes)\n",
    "            for key,value in results.items():\n",
    "                all_results[key].append(value)\n",
    "final_results = segmentation_scores(labels, preds, metrics_names,class_names=class_names,class_no=class_no,weights=c_weights,ignore_class=ignore_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result = {'macro_dice':[],\n",
    " 'micro_dice': [],\n",
    " 'dice_class_1_gleason1': [],\n",
    " 'dice_class_2_gleason3': [],\n",
    " 'dice_class_3_gleason4': [],\n",
    " 'f1_class_1_gleason1': [],\n",
    " 'f1_class_2_gleason3': [],\n",
    " 'f1_class_3_gleason4': [],\n",
    " 'prec_class_1_gleason1': [],\n",
    " 'prec_class_2_gleason3': [],\n",
    " 'prec_class_3_gleason4': [],\n",
    " 'recall_class_1_gleason1': [],\n",
    " 'recall_class_2_gleason3': [],\n",
    " 'recall_class_3_gleason4': [],\n",
    " 'brier': [],\n",
    " 'ce': [],\n",
    " 'accuracy': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for res,value in all_results.items():\n",
    "    final_result[res].append(np.array(value).mean())\n",
    "    final_result[res].append(np.std(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dict_res = {'balanced_metrics':final_results,'all_images':final_result}\n",
    "with open(f'/experiments/{mode}/{folder}/{mode}_path1_results.json', \"w\") as outfile:\n",
    "    json.dump(dict_res, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_results = {}\n",
    "for key,value in all_results.items():\n",
    "    if len(value)!=0:\n",
    "        new_results[key]=value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame.from_dict(new_results)\n",
    "df.to_csv(f'/experiments/{mode}/{folder}/{mode}_path1_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth = pd.read_csv(f'/experiments/smooth_Gleason/2/smooth_Gleason_path1_results.csv')\n",
    "sc = pd.read_csv(f'/experiments/sc_Gleason/2/sc_Gleason_path1_results.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sign_test(smooth['brier'],sc['brier']),sign_test(smooth['accuracy'],sc['accuracy']),sign_test(smooth['ce'],sc['ce'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_test(smooth['micro_dice'],sc['micro_dice']),sign_test(smooth['macro_dice'],sc['macro_dice'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seg_crowd_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
